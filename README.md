# Fraud-Detection
Kaggle-ის კონკურსის მოკლე მიმოხილვა
ამ პროექტის მიზანი იყო ფინანსურ ტრანზაქციებში თაღლითური ქმედებების ამოცნობა Kaggle-ის კონკურსის მონაცემებზე დაყრდნობით. მონაცემები მოიცავდა როგორც რიცხვით, ასევე კატეგორიულ ცვლადებს და მნიშვნელოვანი იყო მოდელების სწორად ფიტინგი და გადატრენინგების თავიდან აცილება.

ჩემი მიდგომა პრობლემის გადასაჭრელად
პრობლემის გადასაჭრელად გამოვიყენე სხვადასხვა Machine Learning მოდელი: Logistic Regression, Random Forest, XGBoost და AdaBoost. თითოეული მოდელის შედეგები შევაფასე Train და Validation AUC-ის სხვაობის მიხედვით, რათა მიმეღო ინფორმაცია მოდელის გადატრენინგებაზე ან ნაკლებ ტრენინგზე. თითოეული მოდელი რამდენჯერმე დავტესტე განსხვავებული პარამეტრებით, რომ მომენახა საუკეთესო კომბინაცია.

რეპოზიტორიის სტრუქტურა
preprocessing/

მონაცემების წინასწარი დამუშავების კლასები

feature_engineering/

ახალი ფიჩერების შექმნის და ტრანსფორმაციის კლასები

feature_selection/

ფიჩერების შერჩევის მეთოდები

models/

სხვადასხვა მოდელების სატრენინგო სკრიპტები

tracking/

MLflow-ის ექსპერიმენტების მართვის სკრიპტები

notebooks/

კვლევითი და ანალიზის ნოუთბუქები

ყველა ფაილის განმარტება
PrepData კლასები — მონაცემების საწყისი გაწმენდა და მომზადება.

FeatureEngineering კლასები — დამატებითი მნიშვნელობების გენერაცია და ტრანსფორმაცია.

CorrelationSelector კლასები — მაღალი კორელაციის მქონე ფიჩერების გაფილტვრა.

Model Training Scripts — თითოეული მოდელის ტრენინგის ცალკეული ფაილები MLflow ინტეგრაციით.

Feature Engineering
კატეგორიული ცვლადების რიცხვითში გადაყვანა
გამოვიყენე WOE (Weight of Evidence) ენკოდირება სხვადასხვა ცვლადების რიცხვითი ფორმატში გადასაყვანად.

Nan მნიშვნელობების დამუშავება
დაკარგული მნიშვნელობები ჩანაცვლდა საშუალო, მედიანური ან სპეციალურად აღებული მნიშვნელობებით ცვლადის ტიპის მიხედვით.

Cleaning მიდგომები
გავასუფთავე უცნაური მნიშვნელობები, გაუქმდა უაზრო ან ზედმეტად მრავალფეროვანი კატეგორიები და დარწმუნებული ვიყავი, რომ მონაცემები მზად იყო მოდელისთვის.

Feature Selection
გამოყენებული მიდგომები და მათი შეფასება
გამოვიყენე კორრელაციური ანალიზი მნიშვნელოვანი ფიჩერების შესარჩევად. ასევე შევამცირე უკიდურესად კორრელირებული ფიჩერების რაოდენობა.

Training
ტესტირებული მოდელები:

Logistic Regression

Random Forest

XGBoost

AdaBoost

Hyperparameter ოპტიმიზაციის მიდგომა
GridSearchCV-ის ნაცვლად გამოვიყენე ხელით შერჩეული პარამეტრების კომბინაციები, რადგან მონაცემთა მოცულობა ძალიან დიდი იყო და GridSearch ძალიან დიდ დროს მოითხოვდა.

საბოლოო მოდელის შერჩევის დასაბუთება
თითოეული მოდელის შედეგები შევადარე Train AUC და Validation AUC მაჩვენებლებს შორის სხვაობის მიხედვით. შევარჩიე ის კონფიგურაციები, რომლებმაც აჩვენეს ყველაზე დაბალი გადატრენინგება და საუკეთესო გენერალიზაცია.

ჩაწერილი მეტრიკების აღწერა
Test ROC AUC — ძირითადი მეტრიკა მოდელების შედარებისთვის.

მოდელის ჰიპერპარამეტრები — ყველა მნიშვნელოვან პარამეტრს ვლოგავდი mlflow-ში.

საუკეთესო მოდელის შედეგები
ყველაზე კარგი შედეგები აჩვენეს XGBoost და Random Forest მოდელებმა, მცირე AUC სხვაობით Train და Validation სეტებზე, რაც მიუთითებს კარგ გენერალიზაციაზე.
